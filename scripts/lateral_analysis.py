#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆæ¨ªå‘æ®‹å·®åˆ†æè„šæœ¬ - æ”¯æŒæ—¶é—´æˆ³èŒƒå›´é™åˆ¶

ä½¿ç”¨æ–¹æ³•:
1. ä¿®æ”¹main()å‡½æ•°ä¸­çš„START_TIMEå’ŒEND_TIMEæ¥è®¾ç½®åˆ†ææ—¶é—´èŒƒå›´
2. è¿è¡Œ: python3 simple_lateral_analysis.py [æ•°æ®ç›®å½•è·¯å¾„]

æ—¶é—´æˆ³ç¤ºä¾‹:
- å¦‚æœä½ çš„æ•°æ®æ—¶é—´æˆ³æ˜¯ 1686651145.123, 1686651200.456 ç­‰
- è®¾ç½® START_TIME = 1686651150.0  # ä»è¿™ä¸ªæ—¶é—´å¼€å§‹åˆ†æ
- è®¾ç½® END_TIME = 1686651180.0    # åˆ°è¿™ä¸ªæ—¶é—´ç»“æŸåˆ†æ
"""

import numpy as np
import pandas as pd
import glob
import os
import sys
import re

def extract_time_delay_from_filename(filename):
    """ä»æ–‡ä»¶åæå–æ—¶é—´å»¶è¿Ÿå€¼"""
    match = re.search(r'_(-?\d+)ms', filename)
    if match:
        return int(match.group(1)) / 1000.0  # è½¬æ¢ä¸ºç§’
    else:
        return 0.0

def analyze_single_file(filepath, start_time=None, end_time=None):
    """åˆ†æå•ä¸ªæ¨ªå‘æ®‹å·®æ–‡ä»¶"""
    try:
        # è¯»å–æ•°æ®ï¼Œè·³è¿‡æ³¨é‡Šè¡Œ
        data = pd.read_csv(filepath, sep=' ', comment='#', 
                          names=['timestamp', 'lateral_residual', 'heading', 'speed', 
                                'utm_residual_x', 'utm_residual_y', 'utm_residual_norm'])
        
        original_count = len(data)
        
        # åº”ç”¨æ—¶é—´æˆ³è¿‡æ»¤
        if start_time is not None:
            data = data[data['timestamp'] >= start_time]
        if end_time is not None:
            data = data[data['timestamp'] <= end_time]
            
        filtered_count = len(data)
        
        if filtered_count == 0:
            print(f"âš ï¸ è­¦å‘Šï¼šæ—¶é—´èŒƒå›´è¿‡æ»¤åæ— æ•°æ® {os.path.basename(filepath)}")
            return None, None, 0, 0
        
        lateral = data['lateral_residual'].values
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        stats = {
            'rms': np.sqrt(np.mean(lateral**2)),
            'std': np.std(lateral),
            'mean': np.mean(lateral),
            'max_abs': np.max(np.abs(lateral)),
            'count': filtered_count
        }
        
        return stats, data, original_count, filtered_count
        
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
        return None, None, 0, 0

def main():
    """ä¸»å‡½æ•°"""
    # ===== æ—¶é—´æˆ³èŒƒå›´è®¾ç½® =====
    # è®¾ç½®ä¸º None è¡¨ç¤ºä¸é™åˆ¶ï¼Œæˆ–è®¾ç½®å…·ä½“çš„èµ·å§‹/ç»“æŸæ—¶é—´æˆ³
    START_TIME = 868905.770    # ä¾‹å¦‚: 1686651145.0
    END_TIME = 869075.894      # ä¾‹å¦‚: 1686651200.0
    
    # å¦‚æœä½ æƒ³åˆ†æç‰¹å®šæ—¶é—´æ®µï¼Œä¿®æ”¹ä¸Šé¢ä¸¤è¡Œï¼Œä¾‹å¦‚ï¼š
    # START_TIME = 1686651145.0  # å¼€å§‹æ—¶é—´æˆ³
    # END_TIME = 1686651200.0    # ç»“æŸæ—¶é—´æˆ³
    # ===============================
    
    if len(sys.argv) > 1:
        data_dir = sys.argv[1]
    else:
        data_dir = "/Users/cjj/work/GNSS_INS/slam/gnss_imu_time/data/ch3"
    
    # æŸ¥æ‰¾æ‰€æœ‰æ¨ªå‘æ®‹å·®æ–‡ä»¶
    pattern = os.path.join(data_dir, "*_lateral.txt")
    files = glob.glob(pattern)
    
    if not files:
        print(f"æœªæ‰¾åˆ°æ¨ªå‘æ®‹å·®æ–‡ä»¶ï¼Œè·¯å¾„: {pattern}")
        print("è¯·ç¡®ä¿å·²è¿è¡ŒESKFå¹¶ç”Ÿæˆäº†æ¨ªå‘æ®‹å·®æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæ¨ªå‘æ®‹å·®æ–‡ä»¶")
    
    # æ˜¾ç¤ºæ—¶é—´èŒƒå›´è®¾ç½®
    if START_TIME is not None or END_TIME is not None:
        print(f"ğŸ“… æ—¶é—´èŒƒå›´é™åˆ¶:")
        if START_TIME is not None:
            print(f"   å¼€å§‹æ—¶é—´: {START_TIME}")
        if END_TIME is not None:
            print(f"   ç»“æŸæ—¶é—´: {END_TIME}")
        print()
    else:
        print("ğŸ“… åˆ†æå…¨éƒ¨æ—¶é—´èŒƒå›´")
        
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ–‡ä»¶çš„æ—¶é—´æˆ³èŒƒå›´ä½œä¸ºå‚è€ƒ
        if files:
            try:
                first_file_data = pd.read_csv(files[0], sep=' ', comment='#', 
                                            names=['timestamp', 'lateral_residual', 'heading', 'speed', 
                                                  'utm_residual_x', 'utm_residual_y', 'utm_residual_norm'])
                min_time = first_file_data['timestamp'].min()
                max_time = first_file_data['timestamp'].max()
                print(f"ğŸ’¡ æ•°æ®æ—¶é—´æˆ³èŒƒå›´å‚è€ƒ: {min_time:.3f} - {max_time:.3f}")
                print(f"   (å¯ç”¨æ­¤èŒƒå›´è®¾ç½®START_TIMEå’ŒEND_TIME)")
            except:
                pass
        print()
    
    print("=" * 80)
    print(f"{'æ—¶é—´å»¶è¿Ÿ(s)':<12} {'RMS(m)':<10} {'æœ€å¤§(m)':<10} {'æ ‡å‡†å·®(m)':<12} {'æ•°æ®ç‚¹':<10} {'è¿‡æ»¤ç‡':<8}")
    print("=" * 80)
    
    results = []
    
    for filepath in sorted(files):
        filename = os.path.basename(filepath)
        time_delay = extract_time_delay_from_filename(filename)
        
        stats, data, original_count, filtered_count = analyze_single_file(
            filepath, START_TIME, END_TIME)
        
        if stats is None:
            continue
        
        results.append((time_delay, stats, filename))
        
        # è®¡ç®—è¿‡æ»¤ç‡
        filter_rate = filtered_count / original_count if original_count > 0 else 0
        
        # æ‰“å°ç»“æœ
        print(f"{time_delay:<12.3f} {stats['rms']:<10.4f} {stats['max_abs']:<10.4f} "
              f"{stats['std']:<12.4f} {stats['count']:<10} {filter_rate*100:<7.1f}%")
    
    if not results:
        print("æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        return
    
    print("=" * 80)
    
    # æ‰¾å‡ºæœ€ä¼˜ç»“æœ
    best_result = min(results, key=lambda x: x[1]['rms'])
    best_delay, best_stats, best_file = best_result
    
    print(f"\nğŸ¯ æœ€ä¼˜æ—¶é—´å»¶è¿Ÿ: {best_delay:.3f}s")
    print(f"   å¯¹åº”RMS: {best_stats['rms']:.4f}m")
    print(f"   æ–‡ä»¶å: {best_file}")
    
    # ç®€å•çš„æ•æ„Ÿæ€§åˆ†æ
    rms_values = [r[1]['rms'] for r in results]
    rms_range = max(rms_values) - min(rms_values)
    
    print(f"\nğŸ“Š æ•æ„Ÿæ€§åˆ†æ:")
    print(f"   RMSèŒƒå›´: {min(rms_values):.4f} - {max(rms_values):.4f}m")
    print(f"   å˜åŒ–å¹…åº¦: {rms_range:.4f}m")
    
    if rms_range > 0.01:  # 1cmä»¥ä¸Šå·®å¼‚æ‰ç®—æ•æ„Ÿ
        print("   âš ï¸  ç³»ç»Ÿå¯¹æ—¶é—´å»¶è¿Ÿæ•æ„Ÿï¼Œå»ºè®®ç²¾ç¡®æ ‡å®š")
    else:
        print("   âœ… ç³»ç»Ÿå¯¹æ—¶é—´å»¶è¿Ÿç›¸å¯¹ä¸æ•æ„Ÿ")

if __name__ == "__main__":
    main()